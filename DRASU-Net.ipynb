{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:02.658215Z",
     "iopub.status.busy": "2025-05-18T18:42:02.657988Z",
     "iopub.status.idle": "2025-05-18T18:42:14.577851Z",
     "shell.execute_reply": "2025-05-18T18:42:14.576885Z",
     "shell.execute_reply.started": "2025-05-18T18:42:02.658192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Define Loss function\n",
    "import tensorflow as tf \n",
    "\n",
    "def dice_metric_loss(y_true, y_pred, smooth=1e-6, alpha=0.25, gamma=2):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    dice_loss = 1 - dice_coefficient\n",
    "\n",
    "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
    "    focal_loss = -alpha * (1 - y_pred) ** gamma * y_true * tf.math.log(y_pred) - (1 - alpha) * y_pred ** gamma * (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "\n",
    "    return dice_loss + tf.reduce_mean(focal_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:14.579388Z",
     "iopub.status.busy": "2025-05-18T18:42:14.578819Z",
     "iopub.status.idle": "2025-05-18T18:42:14.660700Z",
     "shell.execute_reply": "2025-05-18T18:42:14.659842Z",
     "shell.execute_reply.started": "2025-05-18T18:42:14.579359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Define the Model Architecture\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, add, Input, Concatenate, GlobalAveragePooling2D, Dense, Reshape, Multiply, BatchNormalization, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB4, MobileNetV2\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "\n",
    "def squeeze_excite_module(input_tensor, filters):\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Dense(filters // 16, activation='relu')(se)\n",
    "    se = Dense(filters, activation='sigmoid')(se)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    return Multiply()([input_tensor, se])\n",
    "\n",
    "\n",
    "def resnet_module(x, filters, dilation_rate=1):\n",
    "    x1 = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=dilation_rate)(x)\n",
    "    x = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return BatchNormalization()(add([x, x1]))\n",
    "\n",
    "def atrous_module(x, filters):\n",
    "    x = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same', dilation_rate=3)(x)\n",
    "    return BatchNormalization()(x)\n",
    "\n",
    "def RAS_module(x, filters):\n",
    "    x = BatchNormalization()(x)\n",
    "    x1 = atrous_module(x, filters)\n",
    "    x2 = resnet_module(x, filters)\n",
    "    x = add([x1, x2])\n",
    "    x = squeeze_excite_module(x, filters)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "    \n",
    "def create_model(img_height, img_width, input_channels, out_classes, starting_filters):\n",
    "    input_layer = Input(shape=(img_height, img_width, input_channels))\n",
    "    backbone1 = EfficientNetB4(input_tensor=input_layer, include_top=False, weights=\"imagenet\")\n",
    "    backbone2 = MobileNetV2(input_tensor=input_layer, include_top=False, weights='imagenet')\n",
    "\n",
    "    layers1 = [backbone1.get_layer(x).output for x in ['block7a_project_bn', 'block6a_project_bn', 'block4a_project_bn', 'block2a_project_bn']]\n",
    "    layers2 = [backbone2.get_layer(x).output for x in ['block_16_expand_relu', 'block_13_expand_relu', 'block_6_expand_relu', 'block_3_expand_relu']]\n",
    "\n",
    "    p1 = Conv2D(starting_filters * 4, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(layers1[3])\n",
    "    p2 = Conv2D(starting_filters * 8, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(UpSampling2D(2)(layers1[2]))\n",
    "    p3 = Conv2D(starting_filters * 16, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(UpSampling2D(2)(layers1[1]))\n",
    "\n",
    "    q1 = Conv2D(starting_filters * 4, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(layers2[3])\n",
    "    q2 = Conv2D(starting_filters * 8, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(layers2[2])\n",
    "    q3 = Conv2D(starting_filters * 16, 1, padding='same', activation='relu', kernel_initializer=kernel_initializer)(layers2[1])\n",
    "\n",
    "    \n",
    "    c = Conv2D(starting_filters, 3, strides=2, padding='same', activation='relu', kernel_initializer=kernel_initializer)(input_layer)\n",
    "\n",
    "    \n",
    "    l1 = Conv2D(starting_filters * 4, 3, strides=2, padding='same', activation='relu', kernel_initializer=kernel_initializer)(c)\n",
    "    s1 = add([l1, p1, q1])\n",
    "    t1 = RAS_module(s1, starting_filters * 4)\n",
    "\n",
    "    l2 = Conv2D(starting_filters * 8, 2, strides=2, padding='same', activation='relu', kernel_initializer=kernel_initializer)(t1)\n",
    "    s2 = add([l2, p2, q2])\n",
    "    t2 = RAS_module(s2, starting_filters * 8)\n",
    "\n",
    "    l3 = Conv2D(starting_filters * 16, 2, strides=2, padding='same', activation='relu', kernel_initializer=kernel_initializer)(t2)\n",
    "    s3 = add([l3, p3, q3])\n",
    "    t3 = RAS_module(s3, starting_filters * 16)\n",
    "\n",
    "\n",
    "    outd = Concatenate()([UpSampling2D(4)(t3),UpSampling2D(2)(t2),t1])\n",
    "    outd = Conv2D(32, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same')(outd)\n",
    "    outd = BatchNormalization()(outd)\n",
    "    outd = Conv2D(1, 3, activation='relu', kernel_initializer=kernel_initializer, padding='same')(outd)\n",
    "    \n",
    "    \n",
    "    outd = UpSampling2D(4, interpolation='bilinear')(outd)\n",
    "    output = Conv2D(out_classes, 1, activation='sigmoid')(outd)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:16.829255Z",
     "iopub.status.busy": "2025-05-18T18:42:16.828894Z",
     "iopub.status.idle": "2025-05-18T18:42:16.833846Z",
     "shell.execute_reply": "2025-05-18T18:42:16.832756Z",
     "shell.execute_reply.started": "2025-05-18T18:42:16.829227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_size = 352\n",
    "learning_rate = 1e-4\n",
    "filters = 17 \n",
    "b_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Initialize the model for training\n",
    "\n",
    "img_size = 352\n",
    "learning_rate = 1e-4\n",
    "filters = 17\n",
    "b_size = 8\n",
    "\n",
    "\n",
    "opts = tf.keras.optimizers.AdamW(learning_rate = 1e-4)\n",
    "\n",
    "model = create_model(img_height=img_size, img_width=img_size, input_channels=3, out_classes=1, starting_filters=filters)  \n",
    "model.compile(optimizer=opts, loss=dice_metric_loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load weight for further training \n",
    "\n",
    "# weights = np.load(\"path_to_saved_weight_file.npz\")\n",
    "\n",
    "# model = create_model(img_height=img_size, img_width=img_size, input_channels=3, out_classes=1, starting_filters=filters)  \n",
    "# model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate = 1e-4), loss=dice_metric_loss) \n",
    "\n",
    "# model.set_weights([weights[f\"arr_{i}\"] for i in range(len(weights))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For computation of FLOPs\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops/1e9\n",
    "\n",
    "flops = get_flops(model)\n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:25:41.415248Z",
     "iopub.status.busy": "2025-03-26T15:25:41.414919Z",
     "iopub.status.idle": "2025-03-26T15:25:41.432143Z",
     "shell.execute_reply": "2025-03-26T15:25:41.431169Z",
     "shell.execute_reply.started": "2025-03-26T15:25:41.415220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainable_params = sum(tf.keras.backend.count_params(w) for w in model.trainable_weights)\n",
    "non_trainable_params = sum(tf.keras.backend.count_params(w) for w in model.non_trainable_weights)\n",
    "total_params = model.count_params()\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "print(f\"Non-Trainable Parameters: {non_trainable_params}\")\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:24.364487Z",
     "iopub.status.busy": "2025-05-18T18:42:24.364189Z",
     "iopub.status.idle": "2025-05-18T18:42:25.107740Z",
     "shell.execute_reply": "2025-05-18T18:42:25.107124Z",
     "shell.execute_reply.started": "2025-05-18T18:42:24.364463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#general load_data function\n",
    "import glob\n",
    "\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "\n",
    "def load_data(img_height, img_width, data_frame):\n",
    "   \n",
    "    images_to_be_loaded = len(data_frame)\n",
    "\n",
    "    X_train = np.zeros((images_to_be_loaded, img_height, img_width, 3), dtype=np.float32)\n",
    "    Y_train = np.zeros((images_to_be_loaded, img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "    print('Resizing training images and masks: ' + str(images_to_be_loaded))\n",
    "    for n, row in tqdm(enumerate(data_frame.itertuples(index=False)), total=len(data_frame)):\n",
    "        \n",
    "        image_path = row.image\n",
    "        mask_path = row.mask\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        mask = np.zeros((img_height, img_width), dtype=np.bool_)\n",
    "\n",
    "        pillow_image = Image.fromarray(image)\n",
    "\n",
    "        pillow_image = pillow_image.resize((img_height, img_width))\n",
    "        image = np.array(pillow_image)\n",
    "\n",
    "        X_train[n] = image / 255\n",
    "\n",
    "        pillow_mask = Image.fromarray(mask_)\n",
    "        pillow_mask = pillow_mask.resize((img_height, img_width), resample=Image.LANCZOS)\n",
    "        mask_ = np.array(pillow_mask)\n",
    "        \n",
    "        for i in range(img_height):\n",
    "            for j in range(img_width):                \n",
    "                if mask_[i, j] >= 127:                  \n",
    "                    mask[i, j] = 1\n",
    "\n",
    "        Y_train[n] = mask\n",
    "\n",
    "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
    "\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:27.600326Z",
     "iopub.status.busy": "2025-05-18T18:42:27.600021Z",
     "iopub.status.idle": "2025-05-18T18:42:31.591366Z",
     "shell.execute_reply": "2025-05-18T18:42:31.590399Z",
     "shell.execute_reply.started": "2025-05-18T18:42:27.600304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For creation of dataframe for images and masks paths required by training\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "def create_image_mask_df(folder_path,image_dir,mask_dir):\n",
    "    images_path = folder_path + image_dir\n",
    "    masks_path = folder_path + mask_dir\n",
    "    images = sorted([images_path + f for f in os.listdir(images_path)])\n",
    "    masks =sorted([masks_path + f for f in os.listdir(masks_path)])\n",
    "    data = {'image': images, 'mask': masks}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "                                                                          \n",
    "\n",
    "train_df = create_image_mask_df('/kaggle/input/duck-net-splits/Datasets/CVC-ClinicDB/train/',\"images/\",\"masks/\")\n",
    "valid_df = create_image_mask_df('/kaggle/input/duck-net-splits/Datasets/CVC-ClinicDB/validation/',\"images/\",\"masks/\")\n",
    "test_df = create_image_mask_df('/kaggle/input/duck-net-splits/Datasets/CVC-ClinicDB/test/',\"images/\",\"masks/\")\n",
    "\n",
    "\n",
    "print(len(train_df),len(valid_df),len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:34.233370Z",
     "iopub.status.busy": "2025-05-18T18:42:34.232775Z",
     "iopub.status.idle": "2025-05-18T18:44:46.589549Z",
     "shell.execute_reply": "2025-05-18T18:44:46.588658Z",
     "shell.execute_reply.started": "2025-05-18T18:42:34.233341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train = load_data(img_size, img_size, train_df)\n",
    "x_valid, y_valid = load_data(img_size, img_size, valid_df)\n",
    "x_test, y_test = load_data(img_size, img_size, test_df)\n",
    "\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T13:40:19.131673Z",
     "iopub.status.busy": "2025-04-02T13:40:19.131366Z",
     "iopub.status.idle": "2025-04-02T13:40:20.399009Z",
     "shell.execute_reply": "2025-04-02T13:40:20.398288Z",
     "shell.execute_reply.started": "2025-04-02T13:40:19.131651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "aug_train = albu.Compose([\n",
    "    albu.HorizontalFlip(),\n",
    "    albu.VerticalFlip(),\n",
    "    albu.ColorJitter(brightness=(0.6,1.6), contrast=0.2, saturation=0.1, hue=0.01, always_apply=True),\n",
    "    albu.Affine(scale=(0.5,1.5), translate_percent=(-0.125,0.125), rotate=(-180,180), shear=(-22.5,22), always_apply=True),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_images():\n",
    "    x_train_out = []\n",
    "    y_train_out = []\n",
    "\n",
    "    for i in range (len(x_train)):\n",
    "        ug = aug_train(image=x_train[i], mask=y_train[i])\n",
    "        x_train_out.append(ug['image'])  \n",
    "        y_train_out.append(ug['mask'])\n",
    "\n",
    "    return np.array(x_train_out), np.array(y_train_out)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "import gc\n",
    "import time\n",
    "from tensorflow.keras.models import save_model\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "EPOCHS = 5\n",
    "min_loss_for_saving = 100000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "   \n",
    "    print(f'Training, epoch {epoch}')\n",
    "\n",
    "    image_augmented, mask_augmented = augment_images()    \n",
    "    \n",
    "    history = model.fit(x=image_augmented, y=mask_augmented, epochs=1, batch_size=b_size, verbose = 1)\n",
    "    \n",
    "    prediction_valid = model.predict(x_valid, verbose=1)\n",
    "    loss_valid = dice_metric_loss(y_valid, prediction_valid).numpy()\n",
    "    print(\"Loss Validation:\", loss_valid)\n",
    "\n",
    "    #loss_array[epoch+offset] = [history.history['loss'][0], loss_valid]\n",
    "        \n",
    "    dice_valid = f1_score(\n",
    "        np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "        np.ndarray.flatten(prediction_valid > 0.5)\n",
    "    )\n",
    "\n",
    "    print(\"Dice Valid:\", dice_valid)\n",
    "    \n",
    "    \n",
    "    if min_loss_for_saving > loss_valid:\n",
    "        min_loss_for_saving = loss_valid\n",
    "        print(\"Saved model with val_loss:\", loss_valid)\n",
    "       \n",
    "        np.savez(\"model_saved_on_best_val_loss.npz\", *model.get_weights())\n",
    "             \n",
    "\n",
    "\n",
    "    \n",
    "    del image_augmented, mask_augmented, prediction_valid\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:44:46.590875Z",
     "iopub.status.busy": "2025-05-18T18:44:46.590589Z",
     "iopub.status.idle": "2025-05-18T18:44:53.302602Z",
     "shell.execute_reply": "2025-05-18T18:44:53.301904Z",
     "shell.execute_reply.started": "2025-05-18T18:44:46.590847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load the best model weight for inference on test set\n",
    "\n",
    "weights = np.load(\"model_saved_on_best_val_loss.npz\")\n",
    "\n",
    "model = create_model(img_height=img_size, img_width=img_size, input_channels=3, out_classes=1, starting_filters=filters)  \n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate = 1e-4), loss=dice_metric_loss) \n",
    "\n",
    "model.set_weights([weights[f\"arr_{i}\"] for i in range(len(weights))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:45:04.727293Z",
     "iopub.status.busy": "2025-05-18T18:45:04.727010Z",
     "iopub.status.idle": "2025-05-18T18:45:27.586826Z",
     "shell.execute_reply": "2025-05-18T18:45:27.585911Z",
     "shell.execute_reply.started": "2025-05-18T18:45:04.727272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "prediction_test = model.predict(x_test, batch_size=1)\n",
    "\n",
    "\n",
    "loss_test = dice_metric_loss(y_test, prediction_test).numpy()\n",
    "dice_test = f1_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),np.ndarray.flatten(prediction_test > 0.5))\n",
    "miou_test = jaccard_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),np.ndarray.flatten(prediction_test > 0.5))\n",
    "\n",
    "\n",
    "print(dice_test)\n",
    "print(miou_test)\n",
    "print(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:46:29.504982Z",
     "iopub.status.busy": "2025-05-18T18:46:29.504658Z",
     "iopub.status.idle": "2025-05-18T18:46:29.782647Z",
     "shell.execute_reply": "2025-05-18T18:46:29.781711Z",
     "shell.execute_reply.started": "2025-05-18T18:46:29.504947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#To calculate the Hausdorff Distance\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from scipy.ndimage import binary_erosion\n",
    "import numpy as np\n",
    "\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    y_true = np.squeeze(y_true)\n",
    "    y_pred = np.squeeze(y_pred) > 0.5\n",
    "\n",
    "    def get_boundary(mask):\n",
    "        return mask & ~binary_erosion(mask)\n",
    "\n",
    "    distances = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        gt_coords = np.argwhere(get_boundary(y_true[i]))\n",
    "        pred_coords = np.argwhere(get_boundary(y_pred[i]))\n",
    "        if len(gt_coords) == 0 or len(pred_coords) == 0:\n",
    "            distances.append(np.nan)\n",
    "            continue\n",
    "        hd1 = directed_hausdorff(gt_coords, pred_coords)[0]\n",
    "        hd2 = directed_hausdorff(pred_coords, gt_coords)[0]\n",
    "        distances.append(max(hd1, hd2))\n",
    "\n",
    "    \n",
    "    return np.nanmedian(distances)\n",
    "\n",
    "print(hausdorff_distance(y_test, prediction_test))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6886646,
     "sourceId": 11053768,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
